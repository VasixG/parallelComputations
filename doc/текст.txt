ЧТО ТАКОЕ ПАРАЛЛЕЛЬНЫЕ ВЫЧИСЛЕНИЯ
Параллельные вычисления — это метод организации и выполнения вычислений, при котором задача разбивается на более мелкие подзадачи, которые выполняются одновременно или параллельно на нескольких вычислительных ресурсах, таких как процессоры, ядра процессоров или компьютеры.

ИСТОРИЯ ПАРАЛЛЕЛЬНЫХ ВЫЧИСЛЕНИЙ
Исторически параллельные вычисления использовались для научных вычислений и моделирования научных проблем, особенно в естественных и инженерных науках, таких как метеорология. Это привело к разработке параллельного аппаратного и программного обеспечения, а также высокопроизводительных вычислений.

Интерес к параллельным вычислениям уходит корнями в конец 1950-х годов. О необходимости ветвления и ожидания, а также о параллельном программировании, Стэнли Гилл (Ferranti) рассказал в апреле 1958 года. Также в том же году 1958 года исследователи IBM Даниэль Слотник и Джон Кок обсудили использование первого параллелизма в числовых расчетах.

В 1962 году Burroughs Corporation выпустила четырехпроцессорный компьютер D825. Асимметричная многопроцессорная система, первая система Multics от Honeywell, была представлена в 1969 году и могла выполнять до восьми процессоров параллельно.

В 1970-х годах в рамках проекта многопроцессорного компьютера C.mmp в Университете Карнеги-Меллон появились одни из первых многопроцессоров с более чем несколькими процессорами. В ходе этого проекта был запущен суперкомпьютер для научных приложений на базе 64 процессоров Intel 8086/8087, начав новый тип параллельных вычислений. ILLIAC IV была ранней попыткой SIMD параллельных вычислений, созданной ВВС США.

ПРИМЕРЫ ПАРАЛЛЕЛЬНЫХ ВЫЧИСЛЕНИЙ
1. ILLIAC IV
Первый «массивный» параллельный компьютер, построенный в основном в университете Иллинойса в 1960-х годах и разработанный при помощи НАСА и ВВС США. Он имел 64 элемента обработки, способных обрабатывать одновременно 131 072 бита. 
2. Компьютерная система космического шаттла НАСА
Space Shuttle использует 5 компьютеров IBM AP-101 параллельно. Они контролируют авионику шаттла, обрабатывая большие объемы быстро развиваемых данных в реальном времени. Машины могут выполнять 480 000 инструкций в секунду. 
3. Суперкомпьютер Американского саммита
Самый мощный суперкомпьютер на Земле с 200-петафлопсами, которая может обрабатывать 200 квадриллионов операций в секунду. Если бы каждый человек на земле делал 1 расчет в секунду, то ему понадобилось бы 10 месяцев, чтобы сделать то, что Саммит делает за 1 секунду. Он используется для создания новых материалов, понимания геномики, землетрясений, погоды и физики.

ОСНОВНЫЕ МЕТОДЫ И ПРИНЦИПЫ ПВ
Теперь поговорим об основных методах и принципах ПВ. Они включают:
1. Разделение задач (Task Decomposition): задача делится на более мелкие подзадачи, которые могут быть решены независимо друг от друга. Этот подход позволяет распределить нагрузку между различными процессорами или ядрами.
2. Данные в параллельных вычислениях (Data Parallelism): задачи выполняются параллельно над различными наборами данных. Этот метод широко используется в области обработки массивов данных, где каждый элемент обрабатывается параллельно.
3. Задачи в параллельных вычислениях (Task Parallelism): различные задачи выполняются параллельно. Этот метод подходит для задач, которые не зависят друг от друга и могут быть выполнены независимо.
4. Модель исполнения (Execution Model): это определяет, как задачи разделены и как они взаимодействуют друг с другом. Модели исполнения могут включать синхронные (синхронизированные) и асинхронные (несинхронизированные) подходы.
5. Синхронизация (Synchronization): обеспечивает координацию выполнения параллельных задач и предотвращает возможные конфликты при доступе к общим ресурсам.
6. Контроль над структурой (Control Structure): это включает в себя управление потоком выполнения, как задачи создаются, запускаются и завершаются.
7. Распределенные вычисления (Distributed Computing): используется в системах с несколькими вычислительными узлами, где каждый узел выполняет свою часть задачи.
8. Параллельные алгоритмы (Parallel Algorithms): разработка алгоритмов, специально предназначенных для выполнения параллельно, чтобы максимизировать эффективность при использовании множества вычислительных ресурсов.

КЛАССИФИКАЦИЯ ПАРАЛЛЕЛЬНЫХ КОМПЬЮТЕРОВ
Наиболее широко используемая классификация с 1966 года – Таксономия Флинна. Она различает многопроцессорные компьютерные архитектуры в соответствии с тем, как их можно классифицировать по двум независимым измерениям: поток инструкций и поток данных. Каждое из этих измерений может иметь только одно из двух возможных состояний: Single или Multiple. Возможны 4 классификации по Флинну.

• Одна инструкция, одни данные (SISD)
Последовательный (непараллельный) компьютер
Одна инструкция: только один поток команд обрабатывается ЦП в течение одного тактового цикла.
Одиночные данные: только один поток данных используется в качестве входных данных в течение одного тактового цикла.
Детерминированное исполнение
Это самый старый тип компьютера
Примеры: мейнфреймы предыдущего поколения, миникомпьютеры, рабочие станции и однопроцессорные/ядерные ПК.
• Одна инструкция, несколько данных (SIMD)
Тип параллельного компьютера
Одна инструкция: все процессоры выполняют одну и ту же инструкцию в любой заданный такт.
Множественные данные: каждый процессор может работать с разными элементами данных.
Лучше всего подходит для специализированных задач, характеризующихся высокой степенью регулярности, таких как обработка графики/изображений.
Синхронное (шаговое) и детерминированное выполнение
Большинство современных компьютеров, особенно с графическими процессорами (GPU), используют инструкции SIMD и исполнительные блоки.
• Множественные инструкции, отдельные данные (MISD)
Тип параллельного компьютера
Множественные инструкции: каждый процессор обрабатывает данные независимо через отдельные потоки инструкций.
Одиночные данные: один поток данных подается в несколько процессоров.
Фактических примеров этого класса параллельных компьютеров когда-либо существовало немного (если таковые вообще существовали).
• Множественные инструкции, множественные данные (MIMD)
Тип параллельного компьютера
Множественные инструкции: каждый процессор может выполнять отдельный поток инструкций.
Множественные данные: каждый процессор может работать с разными потоками данных.
Выполнение может быть синхронным или асинхронным, детерминированным или недетерминированным.
В настоящее время к этой категории относится наиболее распространенный тип параллельных компьютеров — большинство современных суперкомпьютеров.
Примеры: большинство современных суперкомпьютеров, объединенные в сеть параллельные компьютерные кластеры, многоядерные ПК.

РАЗНИЦА МЕЖДУ ПОСЛЕДОВАТЕЛЬНЫМИ И ПАРАЛЛЕЛЬНЫМИ ВЫЧИСЛЕНИЯМИ
Последовательные и параллельные вычисления представляют собой два различных подхода к выполнению задач. Вот основные различия между ними:

• Определение:
Последовательные вычисления: один процессор обрабатывает программу, инструкция за инструкцией, поочередно.
Параллельные вычисления: несколько процессоров (или ядер) выполняют задачи одновременно, обрабатывая различные части программы параллельно.
• Использование процессоров:
Последовательные вычисления: один процессор.
Параллельные вычисления: несколько процессоров или ядер, работающих параллельно.
• Скорость выполнения:
Последовательные вычисления: ограничены скоростью одного процессора.
Параллельные вычисления: позволяют более высокую общую скорость выполнения, особенно при обработке больших объемов данных.
• Сложность программирования:
Последовательные вычисления: обычно более просты в написании и отладке, так как программы выполняются последовательно.
Параллельные вычисления: требуют более сложного программирования для управления параллельными задачами, синхронизации и обмена данными между процессорами.
• Примеры применения:
Последовательные вычисления: подходят для небольших задач, которые не требуют масштабной параллельности, например, обычные вычисления на домашнем компьютере.
Параллельные вычисления: используются для больших объемов данных, научных исследований, графики, машинного обучения, а также в областях, где необходима высокая производительность.
• Эффективность:
Последовательные вычисления: эффективны для небольших задач, где один процессор может эффективно обрабатывать все инструкции.
Параллельные вычисления: эффективны для задач, которые можно разбить на подзадачи, обрабатываемые параллельно, что приводит к увеличению общей производительности.

ПЛЮСЫ И МИНУСЫ ПВ
Преимущества:
1. Повышенная производительность
Одним из основных преимуществ параллельных вычислений является их способность значительно повысить производительность. Распределяя задачи по нескольким процессорным блокам, параллельные вычисления могут обрабатывать сложные вычисления и операции с интенсивным использованием данных гораздо быстрее, чем последовательные вычисления. Это особенно выгодно в таких задачах, как научное моделирование, анализ данных и рендеринг высококачественной графики.
2. Масштабируемость
Параллельные вычисления предлагают отличную масштабируемость, что означает, что они могут эффективно обрабатывать большие рабочие нагрузки по мере увеличения количества процессоров. По мере развития технологий и появления более мощных процессоров параллельные вычисления могут в полной мере использовать эти ресурсы, обеспечивая более быструю и эффективную обработку данных и задач.
3. Обработка в реальном времени
Некоторые приложения, такие как обработка видео, моделирование в реальном времени и онлайн-игры, требуют быстрой и непрерывной обработки данных. Параллельные вычисления позволяют этим приложениям удовлетворять требования обработки в режиме реального времени, обеспечивая бесперебойный и отзывчивый пользовательский опыт.
4. Использование ресурсов
Параллельные вычисления оптимизируют использование ресурсов за счет одновременного использования нескольких процессоров. Это гарантирует, что никакая вычислительная мощность не используется, максимизируя эффективность аппаратных ресурсов.
Недостатки
1. Сложность
Реализация параллельных вычислений может быть сложной и сложной. Разработка алгоритмов и программ, которые могут быть эффективно распараллелизированы, требует тщательного проектирования и рассмотрения зависимостей между задачами. Кроме того, отладка и тестирование параллельных программ может быть более сложной задачей, чем последовательные.
2. Накладная синхронизация
В параллельных вычислениях задачи часто должны общаться и синхронизироваться друг с другом. Эти накладные расходы на связь могут привести к сложностям и потенциальным узким местам, влияя на общую производительность. Эффективные механизмы синхронизации и балансировка нагрузки необходимы для смягчения этих проблем.
3. Закон Амдала
Закон Амдала гласит, что общее ускорение, полученное при распараллелении вычислений, ограничено последовательной частью алгоритма. Другими словами, если значительная часть вычислений должна выполняться последовательно, потенциальное ускорение параллельных вычислений ограничено, и преимущества могут быть не такими значительными, как ожидалось.
4. Стоимость и инфраструктура
Параллельные вычисления часто требуют специализированного оборудования, такого как многоядерные процессоры, графические процессоры или кластеры взаимосвязанных компьютеров. Приобретение и обслуживание такой инфраструктуры может быть дорогостоящим, особенно для небольших организаций или частных лиц.
Подводя итоги о преимуществах и недостатках, можно сказать, что параллельные вычисления — это мощный подход, который использует возможности нескольких процессоров для повышения производительности и эффективного решения сложных задач. Его способность одновременно обрабатывать задачи предлагает значительные преимущества в различных областях, от научных исследований до мультимедийных приложений. Тем не менее, параллельные вычисления сопряжены с проблемами, включая необходимость тщательного проектирования, накладные расходы на синхронизацию и потенциальные затраты, связанные со специализированным оборудованием. Несмотря на свои недостатки, параллельные вычисления продолжают оставаться критически важной и незаменимой техникой, прокладывая путь к более быстрым, эффективным и масштабируемым вычислениям в современную эпоху.

КАК УЗНАТЬ, ПАРАЛЛЕЛИТСЯ АЛГОРИТМ ИЛИ НЕТ
Определение того, можно ли параллелить алгоритм, зависит от его структуры и характера вычислений. Вот несколько подходов и признаков, которые могут указать на возможность параллельности алгоритма:

1. Зависимости данных:
Если алгоритм содержит независимые части данных или задач, это может быть признаком того, что его можно параллелить. Например, в задачах обработки массивов данных, каждый элемент массива может быть обработан независимо.
2. Разделяй и властвуй:
Если алгоритм построен по принципу "Разделяй и властвуй", где задача разбивается на подзадачи, которые могут быть решены независимо, это обычно улучшает возможность параллельной обработки.
3. Циклы и итерации:
Циклы в алгоритме могут предоставлять возможность для параллельной обработки, особенно если итерации цикла не зависят друг от друга и могут быть выполнены параллельно.
4. Наличие независимых задач:
Если алгоритм включает в себя независимые задачи, которые могут быть выполнены параллельно, это может быть признаком возможности параллелизма.
5. Анализ зависимостей данных:
Использование инструментов анализа зависимостей данных, таких как Data Dependency Analysis, может помочь выявить возможные зависимости между данными и определить, насколько безопасно выполнять операции параллельно.
6. Анализ времени выполнения:
Проведение анализа времени выполнения и оценка времени, затрачиваемого на различные части алгоритма, может помочь выявить узкие места и определить, где возможна параллельная обработка.

ПОЧЕМУ ПВ ВАЖНЫ ДЛЯ НАС?
Без параллельных вычислений выполнение цифровых задач было бы утомительным. Если наши девайсы могли выполнять только 1 операцию за раз, то каждая задача занимала бы гораздо больше времени. Чтобы понять скорость последовательных вычислений, вспомним телефона 2010 года. IPhone 4 использовал последовательный процессор. Открытие email могло занимать до 30 секунд и это без каких-либо вложений. 

СОВРЕМЕННОЕ ПРИМЕНЕНИЕ ПВ
Современные параллельные вычисления имеют широкое применение в различных областях, включая машинное обучение, графику, игровую индустрию и научные исследования. Вот несколько примеров:

1. Машинное обучение и Искусственный Интеллект (ИИ):
Обучение и использование моделей машинного обучения, таких как нейронные сети, требуют больших объемов данных и вычислительных ресурсов. Параллельные вычисления позволяют ускорять процессы обучения, особенно при использовании графических процессоров (GPU) и тензорных процессоров (TPU).
2. Графика и Обработка изображений:
Рендеринг компьютерной графики, обработка изображений и видео - все эти задачи требуют интенсивных вычислений. Параллельные вычисления в графических процессорах (GPU) позволяют быстро обрабатывать графические данные, что особенно важно в игровой индустрии и в виртуальной/дополненной реальности.
3. Игровая Индустрия:
В разработке игр используются сложные графические и физические эффекты, требующие параллельных вычислений. Современные игры могут использовать параллельные вычисления для улучшения графики, физики, искусственного интеллекта персонажей и других аспектов геймплея.
4. Научные исследования:
В научных исследованиях, особенно в областях физики, химии, биологии и климатологии, параллельные вычисления используются для моделирования сложных систем, анализа данных, численного моделирования и обработки огромных объемов информации.
5. Большие данные и аналитика:
Обработка и анализ больших объемов данных становится все более важным. Параллельные вычисления могут ускорить выполнение сложных алгоритмов обработки данных, таких как сжатие, фильтрация и машинное обучение.

БУДУЩЕЕ ПАРАЛЛЕЛЬНЫХ ВЫЧИСЛЕНИЙ
На сколько удивительно, параллельные вычисления могут приближаться к пределу своих возможностей с использованием традиционных процессоров. В ближайшем десятилетии квантовые компьютеры могут значительно улучшить параллельные вычисления. Недавно Google неофициально объявил, что достиг «квантового превосходства». Если это правда, то они построили машину, которая может выполнить за 4 минуты то, что у самого мощного суперкомпьютера на Земле займет 10 000 лет для достижения.
С квантовыми вычислениями параллельная обработка сделает огромный скачок вперёд. Представьте это так: последовательные вычисления делают одну вещь за раз. Параллельный компьютер с 8 ядрами может делать 8 вещей одновременно. Квантовый компьютер с 300 кубитами (квантовыми битами) может выполнять больше операций одновременно, чем количество атомов в нашей вселенной.
Видеока́рта (также видеоада́птер[1], видеопла́та[2], графический ада́птер[1], графи́ческая пла́та, графи́ческая ка́рта, графи́ческий ускори́тель[3]) — устройство, преобразующее графический образ, хранящийся как содержимое памяти компьютера (или самого адаптера), в форму, пригодную для дальнейшего вывода на экран монитора. Обычно видеокарта выполнена в виде печатной платы (плата расширения) и вставляется в слот расширения материнской платы - универсальный, либо специализированный (AGP[4], PCI Express)[5][6].

Также широко распространены и расположенные на системной плате видеокарты — как в виде дискретного отдельного чипа GPU, так и в качестве составляющей части северного моста чипсета или ЦПУ; в случае ЦПУ, встроенный (интегрированный[7]) GPU, строго говоря, не может быть назван видеокартой.

Видеокарты не ограничиваются простым выводом изображения. Они имеют встроенный графический процессор, который может производить дополнительную обработку, снимая эту задачу с центрального процессора компьютера[8]. Например, видеокарты Nvidia и AMD (ATi) осуществляют рендеринг графического конвейера OpenGL, DirectX и Vulkan на аппаратном уровне

Архитектура GPU

Вычислительные блоки. Вычислительные блоки (CU) образуют основные вычислительные элементы в GPU. Каждый CU состоит из набора ядер, которые работают в унисон для одновременного выполнения задач. GPU может содержать от нескольких до нескольких тысяч CU.

Ядра. Ядра — отдельные вычислительные блоки в каждом CU. Хотя они проще своих аналогов в CPU, огромное количество ядер в GPU позволяют выполнять параллельно одну задачу для множества данных. Это важно, например, для рендеринга графики.

Иерархия памяти. Сложная иерархия памяти в GPU разработана, чтобы обеспечивать высокоскоростной доступа к данным. Она включает в себя глобальную, общую, локальную и частную память, каждая из которых имеет свои уникальные характеристики и возможности использования.

Потоковые мультипроцессоры (SMs). В архитектуре NVIDIA GPU потоковый мультипроцессор (SM) служит основным вычислительным блоком, он управляет и выполняет потоки в группах. Каждый SM содержит несколько ядер CUDA, а несколько SM составляют GPU.

Выходные блоки рендеринга (ROPs). ROPs отвечают за финальную стадию рендеринга, когда пиксельные данные выводятся на дисплей. Они выполняют такие операции, как сглаживание и тестирование глубины. Количество ROPs может влиять на способность GPU быстро рендерить изображения высокого разрешения.

Блоки отображения текстур (TMU). TMU выполняют операции с текстурами во время рендеринга графики. Текстуры — это изображения, которые накладывают на 3D-модели для придания им реалистичного вида. TMU отвечают фильтрацию и отображение.

Виды графических процессоров
Есть два вида GPU: интегрированные и специализированные. У каждого вида есть свои характеристики, возможности и сценарии использования.

Интегрированные GPU. Интегрированные GPU встроены в тот же чип, что и центральный процессор (CPU). Они делят ресурсы памяти с CPU, что приводит к высокоэффективному энергопотреблению. Поэтому интегрированные графические процессоры оптимально подходят для устройств, таких как ноутбуки и планшеты, потому что время автономной работы и компактность для них важны в первую очередь.

Специализированные (дискретные) GPU. В специализированных GPU автономные компоненты оснащены собственной выделенной памятью. Процессоры создают с учетом требований производительности,  поэтому они обладают большой вычислительной мощностью. Специализированные GPU подходят для высокопроизводительных систем, таких как игровые ПК и профессиональные рабочие станции.

Преобразование вершин. Первый программируемый этап, в ходе которого отдельные вершины треугольника преобразуются из трехмерного пространства мира в двухмерное пространство экрана.

Сборка формы. Первый из двух фиксированных этапов, где преобразованные вершины преобразуются в фигуры (обычно треугольники).

Растеризация. Второй фиксированный этап. Фигуры (треугольники), полученные на предыдущем этапе, растеризуются в набор пикселей.

Пиксельный шейдер. Второй программируемый этап, где определяется цвет каждого пикселя. Для этого этапа пишется пиксельный шейдер, который вычисляет окончательный цвет пикселя на основе алгоритма и/или текстур.

Виды шейдеров
Шейдеры — это небольшие программы, которые работают на GPU и отвечают за различные аспекты рендеринга пикселей и вершин. Существует несколько видов шейдеров.

Вершинные шейдеры. Обрабатывают атрибуты каждой вершины, такие как ее положение, цвет и текстурные координаты. Они отвечают за преобразование 3D-координат вершин в 2D-координаты, используемые на экране.

Пиксельные (или фрагментные) шейдеры. Определяют цвет каждого пикселя на основе данных вершин и текстуры. Они необходимы для применения таких эффектов, как освещение, тени и текстурирование.

Геометрические шейдеры. Генерируют новые формы на основе входных вершин. Они могут добавлять или удалять вершины для создания новых геометрических форм. Этот тип шейдеров часто используется для сложных эффектов, таких как создание систем частиц.

Существуют и другие виды шейдеров, которые используют в более продвинутых техниках рендеринга.

Тесселяционные шейдеры. Необходимы для увеличения количества полигонов в сетке, что позволяет создавать более детализированные формы и поверхности.

Вычислительные шейдеры. Нужны для выполнения вычислений, которые не обязательно связаны с рендерингом графики, например, симуляции физики или математических расчетов. Они могут работать и манипулировать данными в памяти GPU.